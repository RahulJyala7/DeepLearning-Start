{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of NER tagging using stanford NER tagger in NLTK.\n",
    "\n",
    "An example notebook for using pretrained NER - Named Entity Recognition, provided by stanford using NLTK package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.2.4',\n",
       " '1.11.0',\n",
       " '3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 11:27:44) [MSC v.1900 64 bit (AMD64)]')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras, tensorflow, sys\n",
    "keras.__version__, tensorflow.__version__, sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting path for java\n",
    "\n",
    "Since the stanford librarires are built upon java, java must be installed and one must speicfy its path if not set in environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting path for java executable. Required if not set in Environment variables.\n",
    "import os\n",
    "java_path = r\"C:\\Program Files\\Java\\jdk1.8.0_171\\bin\\java.exe\"\n",
    "os.environ['JAVAHOME'] = java_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Stanford NER tagger\n",
    "\n",
    "Download files of pretrained Stanford NER tagger from -> https://nlp.stanford.edu/software/stanford-ner-2018-10-16.zip. Then give the paths for the files 'english.all.3class.distsim.crf.ser.gz' and 'stanford-ner.jar'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordNERTagger\n",
    "\n",
    "st_ner = StanfordNERTagger('./stanford-ner-2014-06-16/stanford-ner-2014-06-16/classifiers/english.all.3class.distsim.crf.ser.gz',\n",
    "                       './stanford-ner-2014-06-16/stanford-ner-2014-06-16/stanford-ner.jar', encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download necessary NLTK bundles\n",
    "\n",
    "Downloading nltk bundles for handling tokenization of sentence into list of words by considering the punctuation symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Netik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the required nltk bundle, if not already downloaded\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER tags for a sample text. \n",
    "\n",
    "Tokenize the input sentence into words and punctuations and than find the NER tags of the words in a sentence using the above loaded, pretrained Stanford NER tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('In', 'O'), ('an', 'O'), ('interview', 'O'), ('with', 'O'), ('CBS', 'ORGANIZATION'), ('News', 'ORGANIZATION'), ('60', 'O'), ('Minutes', 'O'), ('on', 'O'), ('Friday', 'O'), (',', 'O'), ('Musk', 'PERSON'), ('said', 'O'), (\"'its\", 'O'), ('possible', 'O'), (\"'\", 'O'), ('he', 'O'), ('would', 'O'), ('purchase', 'O'), ('a', 'O'), ('GM', 'ORGANIZATION'), ('factory', 'O'), ('in', 'O'), ('North', 'LOCATION'), ('America', 'LOCATION'), ('if', 'O'), ('the', 'O'), ('company', 'O'), ('is', 'O'), (\"'going\", 'O'), ('to', 'O'), ('sell', 'O'), ('a', 'O'), ('plant', 'O'), ('or', 'O'), ('not', 'O'), ('use', 'O'), ('it', 'O'), (\"'\", 'O'), ('.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "text = \"In an interview with CBS News 60 Minutes on Friday, Musk said 'its possible' he would purchase a GM factory in North America if the company is 'going to sell a plant or not use it'.\"\n",
    "\n",
    "# Tokenize the sentence into list of words and punctuations.\n",
    "tokenized_text = word_tokenize(text)\n",
    "\n",
    "# Find the NER tags for the tokenized sample text\n",
    "tagged_text = st_ner.tag(tokenized_text)\n",
    "\n",
    "# Print the words in the sentence along with there Named-entitiy tags.\n",
    "print(tagged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
